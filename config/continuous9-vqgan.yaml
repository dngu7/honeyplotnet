---
batch_size_per_gpu: 
  continuous: 8
model:
  active: ['continuous','caption'] 
  continuous_data:
    encoder:
      transformer:
        n_layer: 4
        n_head: 4
    decoder:
      transformer:
        n_layer: 4
        n_head: 4
        d_kv: 8
    disc: 
      use: True
    mhd:
      use: False
    vq:
      name: vq
      emb_dim1: 32
      emb_dim2: 32
      n_emb1: 20
      n_emb2: 10
      emb_len1: 4
      emb_len2: 1
train:
  gradient_accum_steps: 8
  intervals:
    snapshot: 1
torch_dist:
  use: true
  deepspeed: false